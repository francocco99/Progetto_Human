{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98d7894c-dfda-4045-9c93-5aca2058b25f",
   "metadata": {},
   "source": [
    "# Sentence Similarity\n",
    "We attempted to calculate the similarity between the review and the plot of the reviewed movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a5526c-0416-4a01-84e1-d8655d6f687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6314c7d0-9b56-445a-9754-af990cb26cf3",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b48367-1eb1-4640-a809-439e38315047",
   "metadata": {},
   "source": [
    "We used pandas to read the dataset, scikit-learn to compute the metric and spaCy Sentence-BERT to calculate the similarity between the plot of the movie and the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88d720a-9d83-43ba-80d2-0f6b23b2d98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy_sentence_bert \n",
    "import spacy\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1fc778-7c88-479d-9cc8-e1afc63b2e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy_sentence_bert.load_model('en_stsb_roberta_large')\n",
    "similarityValue = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c39f5c-31de-4f2d-9089-eab3dc5174c8",
   "metadata": {},
   "source": [
    "### Read the datasets\n",
    "We use the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178f06ce-0409-46df-82d5-8d296b2f1926",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRew=pd.read_json(\"../Dataset/IMDB_reviews.json\",lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b8c1f3-0533-4145-931d-e7ea42a6b1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMovie=pd.read_json('../Dataset/IMDB_movie_details.json',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0af203-c8df-4c88-b4d2-7c53a30d8a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRewS=dataRew[[\"movie_id\",\"review_text\",\"is_spoiler\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b436fdf9-ac78-4ef8-bcfa-88f0eeb80fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRewS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d02fe5-9c26-4697-935e-acdc546007ae",
   "metadata": {},
   "source": [
    "drop the film where the synopsis is not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88d58a8-6a12-483e-bd57-dce15448018a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMovie=dataMovie[dataMovie[\"plot_synopsis\"]!='']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03510999-2ad6-4dbd-ad11-036fc5c7ee4e",
   "metadata": {},
   "source": [
    "We use the end of the plot synopsis to calculate similarity because it is more likely to contain spoilers, we use only the last 512 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a0f27a-9f98-467f-9e06-419330530b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMovie['last'] = dataMovie['plot_synopsis'].apply(lambda x: x[-512:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7c2d0a-c55f-487f-a71c-3504eaf45340",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMovie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37920b0-23db-4768-9c2a-aa56bb59cdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMovieS=dataMovie[[\"last\",\"movie_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f472191-9e1e-4b57-b193-0d0a8159332b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMovieS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322e032d-41d4-4b51-af9a-4854ef6cc22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRewS.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67738e28-261f-42d5-a551-7f36d49dc1f4",
   "metadata": {},
   "source": [
    "### Merge  the two datasets based on movie_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef6aa8c-e6c8-4c8a-825c-7435ceeb6d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSimilar=dataRewS.merge(dataMovieS,left_on=\"movie_id\",right_on=\"movie_id\",how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea99c8e-eaa5-49dd-8ee3-6c7b49d14edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSimilar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7423d47-0832-4300-8d7a-79a47627f42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSimilar=dataSimilar.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba56c56-7531-4e36-ba04-c1ce59b2f5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSimilar=dataSimilar.rename(columns={'last':'endfilm'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349f1fba-93f2-4e6b-9734-9642edbea8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSimilar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91b6f7d-a3a4-42d6-94a7-518139fb8dc9",
   "metadata": {},
   "source": [
    "### Try first on small dataset\n",
    "We first tested the model on a smaller dataset of 2000 rows, with 1000 positive examples and 1000 negative examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69edc169-4b4f-47a0-9d98-385ecd078bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataReducedTrue=dataSimilar[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd04665-80d9-4a6e-b7ba-a85159690c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataReducedFalse=dataSimilar[5200 :6200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffbf816-36f4-439a-bea6-1ed9e00a140c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataReducedFalse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfef01e-7175-44db-b517-ec824bd0d2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataReduced=pd.concat([dataReducedTrue,dataReducedFalse],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6570d011-2bf7-4dac-8abb-da95f95baba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataReduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6444d96a-0dfa-4e59-ab9f-050e5b42a3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataReduced.index = range(0, len(dataReduced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b228b4-e1a1-4955-ae0f-b3e85500ca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataReduced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd07aa49-6db0-4d5f-8497-aa3a5cb7a5fb",
   "metadata": {},
   "source": [
    "Try with 0.30 threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1f04c1-b531-43a5-8dcd-223c6dd04933",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "similarityValue=[]\n",
    "for i in range(dataReduced.count()[0]):\n",
    "    QueryRew=nlp(dataReduced.loc[i][\"review_text\"])\n",
    "    QueryFilm=nlp(dataReduced.loc[i][\"endfilm\"])\n",
    "    Similarity=QueryRew.similarity(QueryFilm)\n",
    "    tuples=(Similarity,dataReduced.loc[i][\"is_spoiler\"])\n",
    "    similarityValue.append(tuples)\n",
    "    if(Similarity>0.30):\n",
    "        tuplesR=(True,dataReduced.loc[i][\"is_spoiler\"])\n",
    "    else:\n",
    "        tuplesR=(False,dataReduced.loc[i][\"is_spoiler\"])\n",
    "    results.append(tuplesR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50a8716-ee89-41da-af3c-999158484e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(results, columns=['Predicted', 'Real']) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20be208-67a0-4a54-8def-778989ff2a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola l'accuracy e l'F1-score\n",
    "accuracy = accuracy_score(dataset['Real'], dataset['Predicted'])\n",
    "f1 = f1_score(dataset['Real'], dataset['Predicted'])\n",
    "recall = recall_score(dataset['Real'], dataset['Predicted'])\n",
    "precision = precision_score(dataset['Real'], dataset['Predicted'])\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy}, F1: {f1}, Precision: {precision}, Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3035bae-359d-41a6-a8c3-9f7a41941417",
   "metadata": {},
   "source": [
    "The results seem encouraging; we can test the model on a dataset of 250,000 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beafff7f-89e9-4a74-85b0-f0be4e46bf89",
   "metadata": {},
   "source": [
    "### Try on a Bigger subset\n",
    "We tested it on a subset approximately half the size of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed24a1a0-6d9e-4355-ba29-d15440819c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177c71db-ef91-4500-b2b0-6564a8a05819",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_data,second_part = train_test_split(dataSimilar, train_size=250000, stratify=dataSimilar['is_spoiler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5f7192-fa90-4ceb-b12e-241beba2eda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_data.index = range(0, len(big_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e9c269-76fe-4839-9c8d-6814177c5852",
   "metadata": {},
   "source": [
    "### Compute the similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd88027-0e85-4a98-ab79-0c9de66c7095",
   "metadata": {},
   "source": [
    "Try with the same threshold as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c237eb-4ba8-4090-8893-7240101d0ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=[]\n",
    "similarityValue=[]\n",
    "for i in range(big_data.count()[0]):\n",
    "    QueryRew=nlp(big_data.loc[i][\"review_text\"])\n",
    "    QueryFilm=nlp(big_data.loc[i][\"endfilm\"])\n",
    "    Similarity=QueryRew.similarity(QueryFilm)\n",
    "    tuples=(Similarity,big_data.loc[i][\"is_spoiler\"])\n",
    "    similarityValue.append(tuples)\n",
    "    if(Similarity>0.30):\n",
    "        tuplesR=(True,big_data.loc[i][\"is_spoiler\"])\n",
    "    else:\n",
    "        tuplesR=(False,big_data.loc[i][\"is_spoiler\"])\n",
    "    results.append(tuplesR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc7ebaa-2c90-427d-aecd-eee82dddf383",
   "metadata": {},
   "source": [
    "### Compute Sentence Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e5ae70-3f19-4992-b28b-9833f7e519c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(results, columns=['Predicted', 'Real'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3655f7cc-d517-47fd-8347-110baa2ec48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola l'accuracy e l'F1-score\n",
    "accuracy = accuracy_score(dataset['Real'], dataset['Predicted'])\n",
    "f1 = f1_score(dataset['Real'], dataset['Predicted'])\n",
    "recall = recall_score(dataset['Real'], dataset['Predicted'])\n",
    "precision = precision_score(dataset['Real'], dataset['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c020b6e-717b-4ef1-8c1d-fd2ac4e72e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {accuracy}, F1: {f1}, Precision: {precision}, Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b481ab-a905-4284-b2a2-0c6ff3545529",
   "metadata": {},
   "source": [
    "### Try to define a new threshold\n",
    "Based on average value of cosine similarity for the two class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d53a134-5813-4a93-a906-a5549f44c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarityValue= pd.DataFrame(similarityValue, columns=['cosine_values', 'Real'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ae1e3f-2d11-45e1-9603-d8b00a16c2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarityValue[similarityValue[\"Real\"]==True][\"cosine_values\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17152bec-63ee-4fb7-ba5d-dbb62c5ce3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarityValue[similarityValue[\"Real\"]==False][\"cosine_values\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc422a0-f33c-4596-97bd-52f01b5051db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSimilar(data):\n",
    "    if data > 0.38:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a531d84-e60c-4d7c-8139-ca517a18f32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarityValue['Predicted']=similarityValue['cosine_values'].apply(computeSimilar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52585286-fbd5-4476-a9b9-f98b481d73f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola l'accuracy e l'F1-score\n",
    "accuracy = accuracy_score(similarityValue['Real'], similarityValue['Predicted'])\n",
    "f1 = f1_score(similarityValue['Real'], similarityValue['Predicted'])\n",
    "recall = recall_score(similarityValue['Real'], similarityValue['Predicted'])\n",
    "precision = precision_score(similarityValue['Real'], similarityValue['Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e0fa0e-5735-43fa-8552-2a678017991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy: {accuracy}, F1: {f1}, Precision: {precision}, Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa86c59d-366f-4fd3-8cc9-018ea6d38e0d",
   "metadata": {},
   "source": [
    "save the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a452c4a3-b308-4884-994b-2a73c3a20878",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Output/outputSentenceSim.txt\", \"a\") as f:\n",
    "    print(f\"Accuracy: {accuracy}, F1: {f1}, Precision: {precision}, Recall: {recall}\",file=f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
