{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRew=pd.read_csv('../Dataset/datiClean.csv')\n",
    "dataMovie=pd.read_csv('../Dataset/movieclean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRew[\"clean_review\"]=dataRew.loc[:,\"clean_review\"].parallel_apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMovie[\"plot_clean\"]=dataMovie.loc[:,\"plot_clean\"].parallel_apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRew.drop(['review_text'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMovie.drop(['plot_synopsis','plot_summary'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Dataset\n",
    "\n",
    "important distribute well the labels in the train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRew.drop(['review_date','movie_id','user_id','rating','review_summary'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=dataRew['clean_review']\n",
    "y=dataRew['is_spoiler']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stratify bilancia i dataset \n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Logistic Regression and Naive Bayes, with k fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for computing the result of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mean():\n",
    "    # Calcola le medie delle metriche\n",
    "    mean_accuracy = np.mean(metrics['accuracy'])\n",
    "    mean_precision = np.mean(metrics['precision'])\n",
    "    mean_recall = np.mean(metrics['recall'])\n",
    "    mean_f1_score = np.mean(metrics['f1_score'])\n",
    "\n",
    "    # Stampa le medie delle metriche\n",
    "    print(\"Mean Accuracy:\", mean_accuracy)\n",
    "    print(\"Mean Precision:\", mean_precision)\n",
    "    print(\"Mean Recall:\", mean_recall)\n",
    "    print(\"Mean F1 Score:\", mean_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_test(y_pred_test):\n",
    "    # Calcolo delle metriche di valutazione sul set di test\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    precision_test = precision_score(y_test, y_pred_test)\n",
    "    recall_test = recall_score(y_test, y_pred_test)\n",
    "    f1_score_test = f1_score(y_test, y_pred_test)\n",
    "\n",
    "    # Stampa delle metriche di valutazione sul set di test\n",
    "    print(\"Test Accuracy:\", accuracy_test)\n",
    "    print(\"Test Precision:\", precision_test)\n",
    "    print(\"Test Recall:\", recall_test)\n",
    "    print(\"Test F1 Score:\", f1_score_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'accuracy': [],\n",
    "    'precision': [],\n",
    "    'recall': [],\n",
    "    'f1_score': []\n",
    "}\n",
    "def computeLogistic(folds,iter,X,y_train):\n",
    "    logistic_reg=LogisticRegression(max_iter=iter)\n",
    "    ## Stratified k-fold grant me a balance division of classes\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    for train_index, val_index in kf.split(X, y_train):\n",
    "        X_fold_train, X_fold_val = X[train_index], X[val_index]\n",
    "        y_fold_train, y_fold_val = y_train[train_index], y_train[val_index]\n",
    "        \n",
    "        # Training\n",
    "        logistic_reg.fit(X_fold_train, y_fold_train)\n",
    "        \n",
    "        # Validation\n",
    "        y_pred = logistic_reg.predict(X_fold_val)\n",
    "        \n",
    "        # Compute metrics\n",
    "        metrics['accuracy'].append(accuracy_score(y_fold_val, y_pred))\n",
    "        metrics['precision'].append(precision_score(y_fold_val, y_pred))\n",
    "        metrics['recall'].append(recall_score(y_fold_val, y_pred))\n",
    "        metrics['f1_score'].append(f1_score(y_fold_val, y_pred))\n",
    "    return logistic_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'accuracy': [],\n",
    "    'precision': [],\n",
    "    'recall': [],\n",
    "    'f1_score': []\n",
    "}\n",
    "def compute_naive(folds,X,y_train):\n",
    "    kf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    naive_bayes = MultinomialNB()\n",
    "    \n",
    "    for train_index, val_index in kf.split(X, y_train):\n",
    "        X_fold_train, X_fold_val = X[train_index], X[val_index]\n",
    "        y_fold_train, y_fold_val = y_train[train_index], y_train[val_index]\n",
    "        \n",
    "        # Training\n",
    "        naive_bayes.fit(X_fold_train, y_fold_train)\n",
    "        \n",
    "        # Validation\n",
    "        y_pred = naive_bayes.predict(X_fold_val)\n",
    "        \n",
    "        # Compute metrics\n",
    "        metrics['accuracy'].append(accuracy_score(y_fold_val, y_pred))\n",
    "        metrics['precision'].append(precision_score(y_fold_val, y_pred))\n",
    "        metrics['recall'].append(recall_score(y_fold_val, y_pred))\n",
    "        metrics['f1_score'].append(f1_score(y_fold_val, y_pred))\n",
    "    return naive_bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first create the text, using the array of vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=[\" \".join(word) for word in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textT=[\" \".join(word) for word in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bag of Words for train\n",
    "vect=CountVectorizer()\n",
    "X=vect.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bag of Words for test\n",
    "X_t=vect.transform(textT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train.values\n",
    "y_test=y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Train and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg=computeLogistic(5,1000,X,y_train)\n",
    "print_mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = logistic_reg.predict(X_t)\n",
    "print_test(y_pred_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Validation, Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes=compute_naive(5,X,y_train)\n",
    "print_mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = naive_bayes.predict(X_t)\n",
    "\n",
    "print_test(y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(text)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(textT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg=computeLogistic(5,1000,X_train_tfidf,y_train)\n",
    "print_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = logistic_reg.predict(X_test_tfidf)\n",
    "print_test(y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes=compute_naive(5,X_train_tfidf,y_train)\n",
    "print_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = naive_bayes.predict(X_test_tfidf)\n",
    "\n",
    "print_test(y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_preWord=dataRew[\"clean_review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_preWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_model = Word2Vec(X_preWord, vector_size=100, window=5, min_count=1, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=word2vec_model.wv.most_similar(\"spoiler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_word2vectrain = [np.mean([word2vec_model.wv[word] for word in text], axis=0) for text in X_preWord]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test,y_train, y_test  = train_test_split(X_word2vectrain,y, test_size=0.2, random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array(X_train)\n",
    "X_test=np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_reg=computeLogistic(5,1000,X_train,y_train)\n",
    "print_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = logistic_reg.predict(X_test)\n",
    "print_test(y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform with normalization\n",
    "i dati devono essere normalizzati perchè essendo negativi, non possiamo applicare il naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_word2vec_normalized = scaler.fit_transform(X_train)\n",
    "X_test_word2vec_normalized = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes=compute_naive(5,X_train_word2vec_normalized,y_train)\n",
    "print_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = naive_bayes.predict(X_test_word2vec_normalized)\n",
    "\n",
    "print_test(y_pred_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
