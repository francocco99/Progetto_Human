{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline with Simple Model\n",
    "\n",
    "In this notebook, we tried simple models like logistic regression and naive Bayes with TF-IDF and bag of words using stratified k-fold cross-validation for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries\n",
    "We used pandas to read the datasets, pandarallel for parallel processing of the dataset, and scikit-learn for the Naive Bayes and Logistic Regression models to split the dataset and compute metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "import ast\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 56 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the dataset\n",
    "This function **ast.literal_eval** is used to convert strings into Python objects, because when we load the cleaned dataset, its contents appeared as strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRew=pd.read_csv('../Dataset/datiClean.csv')\n",
    "dataMovie=pd.read_csv('../Dataset/movieclean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce35855b76f46ca908621bc7c124b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=10249), Label(value='0 / 10249')))…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataRew[\"clean_review\"]=dataRew.loc[:,\"clean_review\"].parallel_apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65576d11f37e4fee8c398158ef24b240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=29), Label(value='0 / 29'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataMovie[\"plot_clean\"]=dataMovie.loc[:,\"plot_clean\"].parallel_apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataMovie.drop(['plot_synopsis','plot_summary'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the Dataset\n",
    "\n",
    "Let's divide the dataset into train and test sets, ensuring that the sets are balanced, we set the same random state in each notebook to ensure consistent division and facilitate better result comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "drop the useless field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataRew.drop(['review_date','movie_id','user_id','rating','review_summary','review_text'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=dataRew['clean_review']\n",
    "y=dataRew['is_spoiler']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Stratify balance the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_spoiler\n",
       "False    338391\n",
       "True     120739\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "is_spoiler\n",
       "False    84598\n",
       "True     30185\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Logistic Regression and Naive Bayes, with k fold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for computing the result of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mean():\n",
    "    # Calculate the averages of the metrics\n",
    "    mean_accuracy = np.mean(metrics['accuracy'])\n",
    "    mean_precision = np.mean(metrics['precision'])\n",
    "    mean_recall = np.mean(metrics['recall'])\n",
    "    mean_f1_score = np.mean(metrics['f1_score'])\n",
    "\n",
    "    # Print the averages of the metrics\n",
    "    print(\"Mean Accuracy:\", mean_accuracy)\n",
    "    print(\"Mean Precision:\", mean_precision)\n",
    "    print(\"Mean Recall:\", mean_recall)\n",
    "    print(\"Mean F1 Score:\", mean_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_test(y_pred_test):\n",
    "    # Calcolo delle metriche di valutazione sul set di test\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    precision_test = precision_score(y_test, y_pred_test)\n",
    "    recall_test = recall_score(y_test, y_pred_test)\n",
    "    f1_score_test = f1_score(y_test, y_pred_test)\n",
    "\n",
    "    # Stampa delle metriche di valutazione sul set di test\n",
    "    print(\"Test Accuracy:\", accuracy_test)\n",
    "    print(\"Test Precision:\", precision_test)\n",
    "    print(\"Test Recall:\", recall_test)\n",
    "    print(\"Test F1 Score:\", f1_score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to train the model, which takes as input the number of folds and the number of iterations to perform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'accuracy': [],\n",
    "    'precision': [],\n",
    "    'recall': [],\n",
    "    'f1_score': []\n",
    "}\n",
    "def computeLogistic(folds,iter,X,y_train):\n",
    "    logistic_reg=LogisticRegression(max_iter=iter)\n",
    "    ## Stratified k-fold grant me a balance division of classes\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    for train_index, val_index in kf.split(X, y_train):\n",
    "        X_fold_train, X_fold_val = X[train_index], X[val_index]\n",
    "        y_fold_train, y_fold_val = y_train[train_index], y_train[val_index]\n",
    "        \n",
    "        # Training\n",
    "        logistic_reg.fit(X_fold_train, y_fold_train)\n",
    "        \n",
    "        # Validation\n",
    "        y_pred = logistic_reg.predict(X_fold_val)\n",
    "        \n",
    "        # Compute metrics\n",
    "        metrics['accuracy'].append(accuracy_score(y_fold_val, y_pred))\n",
    "        metrics['precision'].append(precision_score(y_fold_val, y_pred))\n",
    "        metrics['recall'].append(recall_score(y_fold_val, y_pred))\n",
    "        metrics['f1_score'].append(f1_score(y_fold_val, y_pred))\n",
    "    return logistic_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to train the model, which takes as input the number of folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'accuracy': [],\n",
    "    'precision': [],\n",
    "    'recall': [],\n",
    "    'f1_score': []\n",
    "}\n",
    "def compute_naive(folds,X,y_train):\n",
    "    kf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=42)\n",
    "    naive_bayes = MultinomialNB()\n",
    "    \n",
    "    for train_index, val_index in kf.split(X, y_train):\n",
    "        X_fold_train, X_fold_val = X[train_index], X[val_index]\n",
    "        y_fold_train, y_fold_val = y_train[train_index], y_train[val_index]\n",
    "        \n",
    "        # Training\n",
    "        naive_bayes.fit(X_fold_train, y_fold_train)\n",
    "        \n",
    "        # Validation\n",
    "        y_pred = naive_bayes.predict(X_fold_val)\n",
    "        \n",
    "        # Compute metrics\n",
    "        metrics['accuracy'].append(accuracy_score(y_fold_val, y_pred))\n",
    "        metrics['precision'].append(precision_score(y_fold_val, y_pred))\n",
    "        metrics['recall'].append(recall_score(y_fold_val, y_pred))\n",
    "        metrics['f1_score'].append(f1_score(y_fold_val, y_pred))\n",
    "    return naive_bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Bag of Words\n",
    "To apply Bag of Words, first reconstruct a dummy text from tokens, then apply the function. As a result we have a matrix where each row corresponds to a document and each column corresponds to a token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=[\" \".join(word) for word in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "textT=[\" \".join(word) for word in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bag of Words for train\n",
    "vect=CountVectorizer()\n",
    "X=vect.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Bag of Words for test\n",
    "X_t=vect.transform(textT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train.values\n",
    "y_test=y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Train and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/f.caprari/prova/Group10venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/f.caprari/prova/Group10venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/f.caprari/prova/Group10venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/f.caprari/prova/Group10venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.7641365190686733\n",
      "Mean Precision: 0.5817804667891033\n",
      "Mean Recall: 0.3667166575982666\n",
      "Mean F1 Score: 0.44986233168201845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/f.caprari/prova/Group10venv/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logistic_reg=computeLogistic(5,1000,X,y_train)\n",
    "print_mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7651568612076701\n",
      "Test Precision: 0.5845420746714144\n",
      "Test Recall: 0.36981944674507206\n",
      "Test F1 Score: 0.4530254453958849\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = logistic_reg.predict(X_t)\n",
    "print_test(y_pred_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Validation, Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.7515649162546555\n",
      "Mean Precision: 0.5428177570680055\n",
      "Mean Recall: 0.42837858697856496\n",
      "Mean F1 Score: 0.47335420922726074\n"
     ]
    }
   ],
   "source": [
    "naive_bayes=compute_naive(5,X,y_train)\n",
    "print_mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7410853523605412\n",
      "Test Precision: 0.5081326352530541\n",
      "Test Recall: 0.4822925294020209\n",
      "Test F1 Score: 0.49487549927764085\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = naive_bayes.predict(X_t)\n",
    "\n",
    "print_test(y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(text)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(textT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<459130x240545 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 47974839 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.7607983214630569\n",
      "Mean Precision: 0.5814609280366747\n",
      "Mean Recall: 0.39667934390511417\n",
      "Mean F1 Score: 0.4631081223667101\n"
     ]
    }
   ],
   "source": [
    "logistic_reg=computeLogistic(5,1000,X_train_tfidf,y_train)\n",
    "print_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7797583265814624\n",
      "Test Precision: 0.6580932121446529\n",
      "Test Recall: 0.33821434487328145\n",
      "Test F1 Score: 0.4468029235415117\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = logistic_reg.predict(X_test_tfidf)\n",
    "print_test(y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.755747282904624\n",
      "Mean Precision: 0.6148767691415962\n",
      "Mean Recall: 0.30314977314182534\n",
      "Mean F1 Score: 0.358266525473654\n"
     ]
    }
   ],
   "source": [
    "naive_bayes=compute_naive(5,X_train_tfidf,y_train)\n",
    "print_mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7404406575886673\n",
      "Test Precision: 0.7848837209302325\n",
      "Test Recall: 0.017889680304787145\n",
      "Test F1 Score: 0.03498202312700418\n"
     ]
    }
   ],
   "source": [
    "y_pred_test = naive_bayes.predict(X_test_tfidf)\n",
    "\n",
    "print_test(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### FORSE UTILIZZARE anche embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
