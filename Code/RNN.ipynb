{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56a6087d-6269-4704-a254-e920302e4161",
   "metadata": {},
   "source": [
    "# RNN\n",
    "We used an RNN, this time on the preprocessed text of the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1632899a-43ec-4a56-8ab7-7cbfda0261e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb639e8-ea1b-4a81-9623-b577edfa149f",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "818d89ff-7698-463a-beca-cd9e4025f944",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-19 16:57:28.980674: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a732852-8879-4969-85e0-124f78473f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense,Embedding, Bidirectional, Attention, LSTM, Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bf4414f-5852-462e-a703-d0fe892831e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5974b777-ee4d-4eeb-8c82-e68e0f04340f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f13d0f8-108e-420a-8899-204563a7db7d",
   "metadata": {},
   "source": [
    "### Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5e1cf7a-2136-474d-86fc-746c26e98500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0', '/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "## CHECK GPU\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(get_available_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb24c5ad-aaf6-4354-8641-19a5b3c2ddfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6952b0b0-4eb8-4806-8995-33ab9e63e578",
   "metadata": {},
   "source": [
    "### Functions\n",
    "The first function serves to convert a string into a Python object, the second to create text from tokens, and the last to split the dataset into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6350537c-20f4-4443-a852-3760d99e0144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTIONS DEFINITION\n",
    "\n",
    "#READ SPLIT TOKENS\n",
    "def safe_literal_eval(val):\n",
    "    try:\n",
    "        return ast.literal_eval(val)\n",
    "    except (ValueError, SyntaxError) as e:\n",
    "        print(f\"Error parsing value {val}: {e}\")\n",
    "        return val  # Return the original value if there is an error\n",
    "\n",
    "#MERGE TOKENS AS A WHOLE TEXT\n",
    "def join_tokens(token_list):\n",
    "    if isinstance(token_list, list):\n",
    "        return ' '.join(token_list)\n",
    "    return token_list\n",
    "\n",
    "\n",
    "#SPLIT TRAIN + TEST 80-20\n",
    "def split_train_test(df, label_name):\n",
    "    train, test= train_test_split(df, test_size=0.2, stratify=df[label_name],random_state=42)\n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c94c75-cf39-4816-bc96-317a8d2f6523",
   "metadata": {},
   "source": [
    "### Function metrics\n",
    "Here we have defined the various functions to calculate the metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73e59c91-abb7-4179-ae48-144a4528ebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def precision_m(y_true, y_pred):     \n",
    "    y_pred = tf.nn.sigmoid(y_pred)  # Apply sigmoid to get probabilities   \n",
    "    y_pred = K.round(y_pred)  # Convert probabilities to 0 or 1    \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))     \n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))     \n",
    "    precision = true_positives / (predicted_positives + K.epsilon())     \n",
    "    return precision\n",
    "\n",
    "# Custom metric for recall\n",
    "def recall_m(y_true, y_pred):\n",
    "    y_pred = tf.nn.sigmoid(y_pred)  # Apply sigmoid to get probabilities\n",
    "    y_pred = K.round(y_pred)  # Convert probabilities to 0 or 1\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "# Custom metric for F1 score\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "\n",
    "def false_negative_rate_m(y_true, y_pred):\n",
    "    # Apply sigmoid to get probabilities\n",
    "    y_pred = tf.nn.sigmoid(y_pred)\n",
    "    # Convert probabilities to binary predictions\n",
    "    y_pred = K.round(y_pred)\n",
    "    # Calculate False Negatives\n",
    "    false_negatives = K.sum(K.cast(y_true, dtype='float32') * (1 - y_pred))\n",
    "    # Calculate True Positives + False Negatives (total actual positives)\n",
    "    possible_positives = K.sum(K.cast(y_true, dtype='float32'))\n",
    "    # Calculate False Negative Rate\n",
    "    fnr = false_negatives / (possible_positives + K.epsilon())\n",
    "    return fnr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77d52b4-ebd9-43f8-83c4-ac08c84be47d",
   "metadata": {},
   "source": [
    "###  Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0743baa8-3261-49a3-81a6-13bc04c42c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanData=pd.read_csv(\"../Dataset/datiClean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cb878e4-99bf-4d45-9c25-611d9ca6d012",
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanData=CleanData[[\"clean_review\",\"is_spoiler\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d5b6c2b-ad3c-4340-91a2-602c8590a771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_review</th>\n",
       "      <th>is_spoiler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['oscar', 'year', 'shawshank', 'redemption', '...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['shawshank', 'redemption', 'without', 'doubt'...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['believe', 'film', 'best', 'story', 'ever', '...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['yes', 'spoiler', 'film', 'emotional', 'impac...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['heart', 'extraordinary', 'movie', 'brilliant...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573908</th>\n",
       "      <td>['go', 'wise', 'fast', 'pure', 'entertainment'...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573909</th>\n",
       "      <td>['well', 'shall', 'say', 'one', 'fun', 'rate',...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573910</th>\n",
       "      <td>['go', 'best', 'movie', 'ever', 'seen', 'seen'...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573911</th>\n",
       "      <td>['call', '1999', 'teenage', 'version', 'pulp',...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573912</th>\n",
       "      <td>['movie', 'made', 'doubt', 'sucker', 'family',...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>573913 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             clean_review  is_spoiler\n",
       "0       ['oscar', 'year', 'shawshank', 'redemption', '...        True\n",
       "1       ['shawshank', 'redemption', 'without', 'doubt'...        True\n",
       "2       ['believe', 'film', 'best', 'story', 'ever', '...        True\n",
       "3       ['yes', 'spoiler', 'film', 'emotional', 'impac...        True\n",
       "4       ['heart', 'extraordinary', 'movie', 'brilliant...        True\n",
       "...                                                   ...         ...\n",
       "573908  ['go', 'wise', 'fast', 'pure', 'entertainment'...       False\n",
       "573909  ['well', 'shall', 'say', 'one', 'fun', 'rate',...       False\n",
       "573910  ['go', 'best', 'movie', 'ever', 'seen', 'seen'...       False\n",
       "573911  ['call', '1999', 'teenage', 'version', 'pulp',...       False\n",
       "573912  ['movie', 'made', 'doubt', 'sucker', 'family',...       False\n",
       "\n",
       "[573913 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CleanData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22bb9992-8855-4ca4-8b12-68517dd33229",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = CleanData['is_spoiler']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc05a7cb-1bdd-4c54-bb9c-9ba871002ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanData[\"clean_review\"] = CleanData[\"clean_review\"].apply(safe_literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91d6db5b-5f87-40b5-8dd5-358a2f274fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 573913 entries, 0 to 573912\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   clean_review  573913 non-null  object\n",
      " 1   is_spoiler    573913 non-null  bool  \n",
      "dtypes: bool(1), object(1)\n",
      "memory usage: 4.9+ MB\n"
     ]
    }
   ],
   "source": [
    "CleanData.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec57fb1-b3c4-4bf1-9fe2-52efc41887c6",
   "metadata": {},
   "source": [
    "Create a dummy text thanks to the token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9781a328-96b2-4ec3-a6a0-05df3400a0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanData[\"whole__text\"] = CleanData[\"clean_review\"].apply(join_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43b8ed58-016a-4669-b1cb-7ba41f3ffeb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    oscar year shawshank redemption written direct...\n",
       "1    shawshank redemption without doubt one brillia...\n",
       "2    believe film best story ever told film tell ti...\n",
       "3    yes spoiler film emotional impact find hard wr...\n",
       "4    heart extraordinary movie brilliant indelible ...\n",
       "Name: whole__text, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = CleanData['whole__text']\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be68b2a-3188-4319-a9e0-ab093b7a193e",
   "metadata": {},
   "source": [
    "map the Boolean values in values 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27b89b25-585b-4b06-82d8-3e589af797cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanData['is_spoiler_numeric'] = np.where(CleanData['is_spoiler'] == True, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e181ddae-a300-4b00-b90f-e53a65fbb917",
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanData = CleanData.rename(columns={'is_spoiler_numeric': 'label','whole__text':'text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7687f4d3-b467-4b54-88e0-19a0edc957a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_train_test(CleanData, 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6289031f-6aa0-4e8c-8d58-a14aca880b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[['text','label']]\n",
    "test = test[['text','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c962ed85-e197-4139-b8db-40e4c46ae49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 459130 entries, 94625 to 221631\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    459130 non-null  object\n",
      " 1   label   459130 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 10.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a68017-4915-449f-bf58-77d4e7d5fe84",
   "metadata": {},
   "source": [
    "### Transform the dataset\n",
    "\n",
    "Let's transform the pandas dataset into a TensorFlow dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "15dfbb86-c7fa-44d9-b607-3b9962f84ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            tf.cast(train['text'].values, tf.string),\n",
    "            tf.cast(train['label'].values, tf.int64)\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "564d6cc7-a90d-42de-bfc4-cad08e827e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset =( \n",
    "    tf.data.Dataset.from_tensor_slices(\n",
    "        (\n",
    "            tf.cast(test['text'].values, tf.string),\n",
    "            tf.cast(test['label'].values, tf.int64)\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29e0215d-98b2-4c0b-992a-44f811a4ce18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=(TensorSpec(shape=(), dtype=tf.string, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "025b48dc-1ec8-4f3f-91c5-ab187eba6f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  b'maltese falcon film noir based novel title dashiell hammett directed john huston feature humphrey bogart private investigator sam spade mary astor femme fatale client gladys george peter lorre sydney greenstreet co star key supporting role story follows san francisco private detective dealing three unscrupulous adventurer competing obtain jewel encrusted falcon statuette sam spade hard boiled san francisco private eye unscrupulous next guy also adheres personal code honor office spade archer detective agency sweep miss wonderly offer large retainer sam partner mile archer protect someone named floyd thursby detective believe neither miss wonderly story believe money since archer saw first take case later evening shot death mysterious thursby miss wonderly real name turn brigid shaughnessey story continues sam also introduced effeminate joel cairo fat erudite kasper gutman turn brigid cairo gutman international scoundrel involved search foot high jewel encrusted statuette shape falcon though cairo gutman offer spade small fortune find black bird obviously willing commit mayhem murder towards goal gutman example drug spade allows gunsel wilmer kick beat unconscious detective suspenseful labyrinthine brilliantly cast maltese falcon one influential noirs film still tightest sharpest cynical hollywood official deathless classic bracingly tough even post tarantino standard among important influential movie emerge hollywood system significant way contemporary citizen kane action movie sort least implication character always seem keyed right verge erupting violence turning point picture several respect john huston made directorial debut bogart mostly played bad guy last minute substitution george raft must kicking year afterward role made bogart star established trend setting antihero persona classic movie becomes better multiple viewing indeed'\n",
      "label:  1\n"
     ]
    }
   ],
   "source": [
    "for example, label in training_dataset.take(1):\n",
    "  print('text: ', example.numpy())\n",
    "  print('label: ', label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d4272d-a6f6-44be-b03a-437109812dc2",
   "metadata": {},
   "source": [
    "## RNN MODEL\n",
    "Next, we define the model with its various layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2fc22521-aeb3-4a13-928b-95bec00d0435",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa1e298-a033-4164-9d66-99c7e0178e2f",
   "metadata": {},
   "source": [
    "\n",
    "This code prepares the training and test datasets for training machine learning models using TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa9e8092-eb33-4ae0-8c69-6dd78618a655",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = training_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc74bc77-e151-4e0e-8604-f345f05cad26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690e8c41-1dc3-4b2a-88df-d8c1fb3c4bd4",
   "metadata": {},
   "source": [
    "\n",
    "Once adapted, the encoder can be used to convert textual input data (such as reviews, titles, or any other text) into numerical tensors that can be processed by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5ce79ff-4e90-4311-9f51-eeab074b6a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 10000\n",
    "encoder = tf.keras.layers.TextVectorization(\n",
    "    max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(training_dataset.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f56b960-103e-4ce6-a94e-bde3c6700eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '[UNK]', 'movie', 'film', 'one', 'like', 'character', 'time',\n",
       "       'good', 'story', 'see', 'really', 'make', 'great', 'well', 'would',\n",
       "       'scene', 'get', 'even', 'much'], dtype='<U16')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(encoder.get_vocabulary())\n",
    "vocab[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4256916-2a62-4c0c-9a16-b6071580c753",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.Sequential([\n",
    "    \n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=len(encoder.get_vocabulary()),\n",
    "        output_dim=256,\n",
    "        # Use masking to handle the variable sequence lengths\n",
    "        mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256)),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "632b22c5-8805-4875-b4b7-9701f36c0a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "             metrics=['accuracy',recall_m,precision_m,f1_m,false_negative_rate_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "073aa9a1-d404-439b-91e0-5163dfbea278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text_vectorization (TextVe  (None, None)              0         \n",
      " ctorization)                                                    \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 256)         2560000   \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 512)               1050624   \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3742209 (14.28 MB)\n",
      "Trainable params: 3742209 (14.28 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f334da22-1a4f-492c-9ee5-e61b0b58c330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7174/7174 [==============================] - 387s 53ms/step - loss: 0.4966 - accuracy: 0.7632 - recall_m: 0.2814 - precision_m: 0.6109 - f1_m: 0.3615 - false_negative_rate_m: 0.7186\n",
      "Epoch 2/5\n",
      "7174/7174 [==============================] - 312s 43ms/step - loss: 0.4648 - accuracy: 0.7794 - recall_m: 0.3670 - precision_m: 0.6766 - f1_m: 0.4605 - false_negative_rate_m: 0.6330\n",
      "Epoch 3/5\n",
      "7174/7174 [==============================] - 307s 43ms/step - loss: 0.4495 - accuracy: 0.7865 - recall_m: 0.4008 - precision_m: 0.6854 - f1_m: 0.4927 - false_negative_rate_m: 0.5992\n",
      "Epoch 4/5\n",
      "7174/7174 [==============================] - 307s 43ms/step - loss: 0.4352 - accuracy: 0.7926 - recall_m: 0.4318 - precision_m: 0.6927 - f1_m: 0.5193 - false_negative_rate_m: 0.5682\n",
      "Epoch 5/5\n",
      "7174/7174 [==============================] - 306s 43ms/step - loss: 0.4173 - accuracy: 0.8007 - recall_m: 0.4804 - precision_m: 0.6993 - f1_m: 0.5577 - false_negative_rate_m: 0.5196\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5782a571-0f88-45cf-b845-ae13bda8e799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy values for each epoch:\n",
      "Epoch 0: 0.7632086873054504 recall: 0.2814015746116638 precision: 0.61093670129776 f1-score: 0.3615213632583618 \n",
      "Epoch 1: 0.7793631553649902 recall: 0.3670152723789215 precision: 0.6765910387039185 f1-score: 0.46051326394081116 \n",
      "Epoch 2: 0.7864766120910645 recall: 0.40077152848243713 precision: 0.6854116320610046 f1-score: 0.4926777184009552 \n",
      "Epoch 3: 0.792590320110321 recall: 0.43183839321136475 precision: 0.6927367448806763 f1-score: 0.5193272829055786 \n",
      "Epoch 4: 0.8007187247276306 recall: 0.4804462194442749 precision: 0.6993305683135986 f1-score: 0.5576528906822205 \n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy values for each epoch:\")\n",
    "for epoch in range(len(history.history['accuracy'])):\n",
    "    accuracy = history.history['accuracy'][epoch]\n",
    "    precision = history.history['precision_m'][epoch]\n",
    "    recall = history.history['recall_m'][epoch]\n",
    "    f1_score = history.history['f1_m'][epoch]\n",
    "    print(f\"Epoch {epoch}: {accuracy} \" f\"recall: {recall} \" f\"precision: {precision} \" f\"f1-score: {f1_score} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2fab53a3-303b-425a-9d30-b915bbaf4107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Media Training accuracy: 0.7844714999198914\n",
      "    Media Training precision: 0.6730013370513916\n",
      "    Media Training recall: 0.39229459762573243\n",
      "    Media Training F1 score: 0.47833850383758547\n"
     ]
    }
   ],
   "source": [
    "training_accuracy_mean = np.mean(history.history['accuracy'])\n",
    "training_precision_mean = np.mean(history.history['precision_m'])\n",
    "training_recall_mean = np.mean(history.history['recall_m'])\n",
    "training_f1_score_mean = np.mean(history.history['f1_m'])\n",
    "\n",
    "print(f\"    Media Training accuracy: {training_accuracy_mean}\")\n",
    "print(f\"    Media Training precision: {training_precision_mean}\")\n",
    "print(f\"    Media Training recall: {training_recall_mean}\")\n",
    "print(f\"    Media Training F1 score: {training_f1_score_mean}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e990d0c-263a-4792-aaa5-9aa7b8ae6ca2",
   "metadata": {},
   "source": [
    "### Result obtained\n",
    "Accuracy values for each epoch:\n",
    "Epoch 0: 0.7632086873054504 recall: 0.2814015746116638 precision: 0.61093670129776 f1-score: 0.3615213632583618 \n",
    "Epoch 1: 0.7793631553649902 recall: 0.3670152723789215 precision: 0.6765910387039185 f1-score: 0.46051326394081116 \n",
    "Epoch 2: 0.7864766120910645 recall: 0.40077152848243713 precision: 0.6854116320610046 f1-score: 0.4926777184009552 \n",
    "Epoch 3: 0.792590320110321 recall: 0.43183839321136475 precision: 0.6927367448806763 f1-score: 0.5193272829055786 \n",
    "Epoch 4: 0.8007187247276306 recall: 0.4804462194442749 precision: 0.6993305683135986 f1-score: 0.5576528906822205\n",
    "\n",
    "Media Training accuracy: 0.7844714999198914\n",
    "    Media Training precision: 0.6730013370513916\n",
    "    Media Training recall: 0.39229459762573243\n",
    "    Media Training F1 score: 0.47833850383758547\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "281b3aea-f7c9-45ab-ad37-c813e70aadef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1794/1794 [==============================] - 30s 17ms/step - loss: 0.5010 - accuracy: 0.7817 - recall_m: 0.4375 - precision_m: 0.5841 - f1_m: 0.4915 - false_negative_rate_m: 0.5625\n"
     ]
    }
   ],
   "source": [
    "resultTest=model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a6f0fb31-f656-4f24-8e3b-002689b3348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Output/outputRNN.txt\", \"a\") as f:\n",
    "   for epoch in range(len(history.history['accuracy'])):\n",
    "        accuracy = history.history['accuracy'][epoch]\n",
    "        precision = history.history['precision_m'][epoch]\n",
    "        recall = history.history['recall_m'][epoch]\n",
    "        f1_score = history.history['f1_m'][epoch]\n",
    "        print(f\"Epoch {epoch}: {accuracy} \" f\"recall: {recall} \" f\"precision: {precision} \" f\"f1-score: {f1_score} \",file=f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "22b9b8ea-8aa3-4fad-b506-c2162c711d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../Output/outputRNN.txt\", \"a\") as f:\n",
    "    print(\"Test Result\",file=f)\n",
    "    print(f\"  Loss: {resultTest[0]}, Accuracy: {resultTest[1]}, F1: {resultTest[4]}, Precision: {resultTest[3]}, Recall: {resultTest[2]}\",file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "42c10bac-fc2e-461b-8827-74831e92f6ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5010486841201782, 0.7816836833953857, 0.4375437796115875, 0.5841323733329773, 0.4914727210998535, 0.5624560713768005]\n"
     ]
    }
   ],
   "source": [
    "print(resultTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "080cdfa0-c8bc-40e8-82e0-a3be0c1728ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Loss: 0.5010486841201782, Accuracy: 0.7816836833953857, F1: 0.4914727210998535, Precision: 0.5841323733329773, Recall: 0.4375437796115875\n"
     ]
    }
   ],
   "source": [
    "print(f\"  Loss: {resultTest[0]}, Accuracy: {resultTest[1]}, F1: {resultTest[4]}, Precision: {resultTest[3]}, Recall: {resultTest[2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bd8913-81a7-41ab-b3a5-b046a2745909",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultTest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
